{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VjYy0F2gZIPR"
      },
      "outputs": [],
      "source": [
        "!pip install pygit2==1.15.1\n",
        "%cd /content\n",
        "!git clone https://github.com/lllyasviel/Fooocus.git\n",
        "%cd /content/Fooocus\n",
        "!python entry_with_update.py --share --always-high-vram\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python backend.py \\\n",
        "  --prompt \"a serene landscape with mountains\" \\\n",
        "  --negative_prompt \"lowres\" \\\n",
        "  --seed 42 \\\n",
        "  --base_model sd-v1.5.ckpt \\\n",
        "  --steps 30 \\\n",
        "  --cfg_scale 7.5 \\\n",
        "  --width 512 \\\n",
        "  --height 512 \\\n",
        "  --n_images 2\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mpSfnYBUxTxC",
        "outputId": "22537b16-b00d-4c2a-f6a7-a86aeb56dc6b"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load preset [/content/Fooocus/presets/initial.json] failed\n",
            "\n",
            "Overriding config value path_outputs with outputs\n",
            "Using temp path /content/Fooocus/temp\n",
            "Total VRAM 15095 MB, total RAM 12978 MB\n",
            "Set vram state to: NORMAL_VRAM\n",
            "Device: cuda:0 Tesla T4 : native\n",
            "VAE dtype: torch.float32\n",
            "Generating with parameters: {'prompt': 'a serene landscape with mountains', 'negative_prompt': 'lowres', 'seed': 42, 'steps': 30, 'cfg_scale': 7.5, 'width': 512, 'height': 512, 'n_images': 2, 'base_model': 'sd-v1.5.ckpt', 'refiner_model': None, 'vae': None, 'loras': [], 'controlnets': [], 'output_path': 'outputs', 'temp_path': 'temp', 'preset': 'initial', 'rebuild_hash_cache': 0, 'disable_preset_selection': False, 'disable_image_log': False, 'disable_metadata': False, 'disable_enhance_output_sorting': False, 'gpu_device_id': None, 'hf_mirror': None}\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/Fooocus/backend.py\", line 95, in <module>\n",
            "    out_files = generate_image(params)\n",
            "                ^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/Fooocus/backend.py\", line 59, in generate_image\n",
            "    pipeline = model_management.get_model(\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "AttributeError: module 'ldm_patched.modules.model_management' has no attribute 'get_model'\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}